akka {
  actor {
    default-dispatcher {

//      executor = "default-executor"
      executor = "affinity-pool-executor"

      fork-join-executor {
        # Settings this to 1 instead of 3 seems to improve performance.
        parallelism-factor = 1.0

        # default.
        parallelism-min = 4
        parallelism-max = 24

        task-peeking-mode = FIFO
      }

      # This will be used if you have set "executor = "affinity-pool-executor""
      # Underlying thread pool implementation is akka.dispatch.affinity.AffinityPool.
      # This executor is classified as "ApiMayChange".
      affinity-pool-executor {
        # Min number of threads to cap factor-based parallelism number to
        parallelism-min = 4

        # The parallelism factor is used to determine thread pool size using the
        # following formula: ceil(available processors * factor). Resulting size
        # is then bounded by the parallelism-min and parallelism-max values.
        parallelism-factor = 1

        # Max number of threads to cap factor-based parallelism number to.
        parallelism-max = 24

        # Each worker in the pool uses a separate bounded MPSC queue. This value
        # indicates the upper bound of the queue. Whenever an attempt to enqueue
        # a task is made and the queue does not have capacity to accomodate
        # the task, the rejection handler created by the rejection handler specified
        # in "rejection-handler" is invoked.
        task-queue-size = 512

        # FQCN of the Rejection handler used in the pool.
        # Must have an empty public constructor and must
        # implement akka.actor.affinity.RejectionHandlerFactory.
        rejection-handler = "akka.dispatch.affinity.ThrowOnOverflowRejectionHandler"

        # Level of CPU time used, on a scale between 1 and 10, during backoff/idle.
        # The tradeoff is that to have low latency more CPU time must be used to be
        # able to react quickly on incoming messages or send as fast as possible after
        # backoff backpressure.
        # Level 1 strongly prefer low CPU consumption over low latency.
        # Level 10 strongly prefer low latency over low CPU consumption.
        idle-cpu-level = 1

        # FQCN of the akka.dispatch.affinity.QueueSelectorFactory.
        # The Class of the FQCN must have a public constructor with a
        # (com.typesafe.config.Config) parameter.
        # A QueueSelectorFactory create instances of akka.dispatch.affinity.QueueSelector,
        # that is responsible for determining which task queue a Runnable should be enqueued in.
        queue-selector = "akka.dispatch.affinity.FairDistributionHashCache"

        # When using the "akka.dispatch.affinity.FairDistributionHashCache" queue selector
        # internally the AffinityPool uses two methods to determine which task
        # queue to allocate a Runnable to:
        # - map based - maintains a round robin counter and a map of Runnable
        # hashcodes to queues that they have been associated with. This ensures
        # maximum fairness in terms of work distribution, meaning that each worker
        # will get approximately equal amount of mailboxes to execute. This is suitable
        # in cases where we have a small number of actors that will be scheduled on
        # the pool and we want to ensure the maximum possible utilization of the
        # available threads.
        # - hash based - the task - queue in which the runnable should go is determined
        # by using an uniformly distributed int to int hash function which uses the
        # hash code of the Runnable as an input. This is preferred in situations where we
        # have enough number of distinct actors to ensure statistically uniform
        # distribution of work across threads or we are ready to sacrifice the
        # former for the added benefit of avoiding map look-ups.
        fair-work-distribution {
          # The value serves as a threshold which determines the point at which the
          # pool switches from the first to the second work distribution schemes.
          # For example, if the value is set to 128, the pool can observe up to
          # 128 unique actors and schedule their mailboxes using the map based
          # approach. Once this number is reached the pool switches to hash based
          # task distribution mode. If the value is set to 0, the map based
          # work distribution approach is disabled and only the hash based is
          # used irrespective of the number of unique actors. Valid range is
          # 0 to 2048 (inclusive)
          threshold = 128
        }
      }

    }
  }
}


